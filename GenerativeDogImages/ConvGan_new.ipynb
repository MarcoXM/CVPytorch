{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import torch\nfrom torchvision import datasets,transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tqdm import tqdm_notebook as tqdm\nfrom torchvision.utils import save_image\nfrom torch.autograd import Variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed = 224):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \nseed_everything()    \n\n# 这里只是为了保证我们的可复现性\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 256\nIMAGE_SIZE = 64\ndef tensorGenerater(path = '../input/all-dogs/',batch_size = BATCH_SIZE,ouputimg_size = IMAGE_SIZE,rotate_size = 10):\n    train_transform = transforms.Compose([transforms.Resize(64),\n                                          transforms.RandomHorizontalFlip(),\n                                            transforms.RandomRotation(rotate_size), # 我们的目标size 是64 by 64 呀！\n                                            transforms.CenterCrop(ouputimg_size),\n                                            transforms.ToTensor(),\n                                            transforms.Normalize(mean=[.5,.5,.5],\n                                                                 std =[.5,.5,.5])]) #保证数字在-1，1之间\n    traindata = datasets.ImageFolder(path,transform=train_transform)\n    trainloader = torch.utils.data.DataLoader(traindata,batch_size,shuffle=True)\n    return trainloader\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainloader = tensorGenerater()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"看看data"},{"metadata":{"trusted":true},"cell_type":"code","source":"imgs, label = iter(trainloader).next()\nimgs.size(),label.size() # 一个batch 的data（tensor）\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = imgs[0]\n\nprint('Min: ', imgs.min())\nprint('Max: ', imgs.max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"看看狗子"},{"metadata":{"trusted":true},"cell_type":"code","source":"def imshow(img):\n    img = img / 2 + 0.5  # unnormalize，从（-1，1） >>>>>>>> （0，1）\n    plt.imshow(np.transpose(img, (1, 2, 0))) #因为numpy plot 要通道数在最后\n    \nfig = plt.figure(figsize=(25, 16))\nfor idx in range(64):\n    ax = fig.add_subplot(8, 8, idx+1, xticks=[], yticks=[])\n    imshow(imgs[idx])\n    ax.set_title(\"{}\".format(label[idx])) # ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"这是时候就是model 的结构了，GAN 有两个部分Generator 和 Descriminator。先做Descriminator。"},{"metadata":{"trusted":true},"cell_type":"code","source":"def conv(inchanel,outchanel,kernelsize = 4,stride = 2,padding = 1 ,BN = True):\n    layers = []\n    conv_layer = nn.Conv2d(inchanel,outchanel,kernelsize,\n                           stride=stride,padding= padding,bias=False)\n    layers.append(conv_layer)\n    if BN:\n        layers.append(nn.BatchNorm2d(outchanel))\n    \n    return nn.Sequential(*layers)\n\nclass Des(nn.Module):\n    def __init__(self,conv_dim = 32):\n        super(Des,self).__init__()\n        self.conv_dim = conv_dim\n        \n        # layers\n        self.conv1 = conv(3,conv_dim * 2, 4)\n        self.conv2 = conv(conv_dim * 2, conv_dim * 4, 4,BN=False)\n        self.conv3 = conv(conv_dim * 4, conv_dim * 8, 4,BN=False)\n        self.conv4 = conv(conv_dim * 8, conv_dim * 16,4)\n        self.conv5 = nn.Conv2d(conv_dim * 16,1,4,1,0,bias=False) # 256 >>>1 , 4 by 4 >>>> 1 by 1\n        \n    def forward(self,x):\n        x = F.leaky_relu(self.conv1(x),0.2) #64 * 32 * 32\n        x = F.leaky_relu(self.conv2(x),0.2) # 128 * 16 * 16 \n        x = F.leaky_relu(self.conv3(x),0.2) # 256 * 8 * 8 \n        x = F.leaky_relu(self.conv4(x),0.2) # 512 * 4 * 4\n        x = torch.sigmoid(self.conv5(x)).view(-1,1)\n        \n        return x\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"def tconv(inchanel,outchanel,kernelsize = 4,stride = 2,padding = 1 ,BN = True):\n    layers = []\n    conv_layer = nn.ConvTranspose2d(inchanel,outchanel,kernelsize,\n                                   stride=stride,padding=padding)\n    layers.append(conv_layer)\n    if BN:\n        layers.append(nn.BatchNorm2d(outchanel))\n    \n    return nn.Sequential(*layers)\n\n\nclass Generator(nn.Module):\n    def __init__(self,z_size,conv_dim = 32):\n        super(Generator,self).__init__()\n        self.conv_dim = conv_dim\n        self.z = z_size\n        \n        self.conv0 = tconv(z_size,conv_dim * 32,4,1,0)\n        self.conv1 = tconv(conv_dim * 32,conv_dim * 16,4)\n        self.conv2 = tconv(conv_dim * 16,conv_dim * 8,4) # 256,16,16\n        self.conv3 = tconv(conv_dim * 8,conv_dim *4,4) # 128,32,32\n        self.conv4 = tconv(conv_dim * 4,conv_dim *2,4) # 64,64,64\n        self.conv5 = nn.ConvTranspose2d(conv_dim *2,3,3,1,1) # 3,64,64\n        \n    def forward(self,x):\n        x = x.view(-1,self.z,1,1)\n        x = F.relu(self.conv0(x)) # 1024 * 4 * 4\n        x = F.relu(self.conv1(x)) # 512 * 8 * 8\n        #print(x.size())\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))# 256* 16*16\n        x = F.relu(self.conv4(x))\n        x = torch.tanh(self.conv5(x)) # 128\n        \n        return x\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def weights_init(m):\n    \"\"\"\n    Takes as input a neural network m that will initialize all its weights.\n    \"\"\"\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define hyperparams\nCONV_DIM = 32\nZ_SIZE = 100\n\n# define discriminator and generator\nD = Des(CONV_DIM)\n#D.apply(weights_init)\nG = Generator(Z_SIZE, CONV_DIM)\n#G.apply(weights_init)\nprint(D)\nprint()\nprint(G)\n\ntrain_on_gpu = torch.cuda.is_available()\n\nif train_on_gpu:\n    # move models to GPU\n    G.cuda()\n    D.cuda()\n    print('GPU available for training. Models moved to GPU')\nelse:\n    print('Training on CPU.')\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Des 的loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"def real_loss(D_out, smooth=False):\n    batch_size = D_out.size(0)\n    if smooth:\n        labels = torch.ones(batch_size)*0.9\n    else:\n        labels = torch.ones(batch_size) # real labels = 1 \n    if train_on_gpu:\n        labels = labels.cuda()\n    # binary cross entropy with logits loss\n    criterion = nn.BCELoss()\n    # calculate loss\n    loss = criterion(D_out.squeeze(), labels)\n    return loss\n\ndef fake_loss(D_out):\n    batch_size = D_out.size(0)\n    labels = Variable(torch.zeros(batch_size)) # fake labels = 0\n    if train_on_gpu:\n        labels = labels.cuda()\n    criterion = nn.BCELoss()\n    # calculate loss\n    loss = criterion(D_out.squeeze(), labels)\n    return loss\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR_G = 0.002\nLR_D = 0.0002\nbeta1= 0.5\nbeta2= 0.999\n\n# Create optimizers for the discriminator and generator\nd_optimizer = optim.Adam(D.parameters(), lr = LR_D,betas=[beta1, beta2])\ng_optimizer = optim.Adam(G.parameters(), lr = LR_G,betas=[beta1, beta2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle as pkl\n\n# training hyperparams\nnum_epochs = 100\n\n# keep track of loss and generated, \"fake\" samples\nsamples = []\nlosses = []\n\nprint_every = 300\n\n# Get some fixed data for sampling. These are images that are held\n# constant throughout training, and allow us to inspect the model's performance\nsample_size=16\nfixed_z = np.random.uniform(-1, 1, size=(sample_size, Z_SIZE))\nfixed_z = torch.from_numpy(fixed_z).float()\n\n# train the network\nfor epoch in tqdm(range(num_epochs)):\n    for batch_i, (real_images, _) in enumerate(trainloader):     \n        batch_size = real_images.size(0)\n        # ============================================\n        #            TRAIN THE DISCRIMINATOR\n        # ============================================\n        d_optimizer.zero_grad()\n        \n        # 1. Train with real images\n        # Compute the discriminator losses on real images \n        if train_on_gpu:\n            real_images = real_images.cuda()\n        D_real = D(real_images)\n        d_real_loss = real_loss(D_real,smooth=True)\n        d_real_loss.backward()\n        D_real = D_real.mean().item()\n        \n        \n        # 2. Train with fake images\n        # Generate fake images\n        z = np.random.uniform(-1, 1, size=(batch_size, Z_SIZE))\n        z = torch.from_numpy(z).float()\n        # move x to GPU, if available\n        if train_on_gpu:\n            z = z.cuda()\n            \n        fake_images = G(z)\n        # Compute the discriminator losses on fake images            \n        D_fake = D(fake_images.detach())\n        d_fake_loss = fake_loss(D_fake)\n        d_fake_loss.backward()\n        D_fake_1 = D_fake.mean().item()\n        # add up loss and perform backprop\n        d_loss = d_real_loss + d_fake_loss\n        d_optimizer.step()\n        \n        # =========================================\n        #            TRAIN THE GENERATOR\n        # =========================================\n        g_optimizer.zero_grad()\n        \n        # 1. Train with fake images and flipped labels\n        # Compute the discriminator losses on fake images \n        D_fake = D(fake_images)\n        g_loss = real_loss(D_fake,smooth=True) # use real loss to flip labels\n        D_fake_2 = D_fake.mean().item()\n        # perform backprop\n        g_loss.backward()\n        g_optimizer.step()\n\n        # Print some loss stats\n        if batch_i % print_every == 0:\n            # append discriminator loss and generator loss\n            losses.append((d_loss.item(), g_loss.item()))\n            # print discriminator and generator loss\n            print('Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}| Dreal_loss: {:6.4f}| Dfake1_loss: {:6.4f}| Dfake2_loss: {:6.4f}'.format(\n                    epoch+1, num_epochs, d_loss.item(), g_loss.item(), D_real,D_fake_1,D_fake_2))\n\n    \n    ## AFTER EACH EPOCH##    \n    # generate and save sample, fake images\n    G.eval() # for generating samples\n    if train_on_gpu:\n        fixed_z = fixed_z.cuda()\n    samples_z = G(fixed_z)\n    samples.append(samples_z)\n    G.train() # back to training mode\n\n\n# Save training generator samples\nwith open('train_samples.pkl', 'wb') as f:\n    pkl.dump(samples, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nlosses = np.array(losses)\nplt.plot(losses.T[0], label='Discriminator', alpha=0.5)\nplt.plot(losses.T[1], label='Generator', alpha=0.5)\nplt.title(\"Training Losses\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samples[0].size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def view_samples(epoch, samples):\n    fig, axes = plt.subplots(figsize=(16,4), nrows=2, ncols=8, sharey=True, sharex=True)\n    for ax, img in zip(axes.flatten(), samples[epoch]):\n        img = img.detach().cpu().numpy()\n        img = np.transpose(img, (1, 2, 0))\n        \n        ax.xaxis.set_visible(False)\n        ax.yaxis.set_visible(False)\n        im = ax.imshow(img.reshape((64,64,3)))\n\n_ = view_samples(-1, samples)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if not os.path.exists('../output_images'):\n    os.mkdir('../output_images')\n    \nim_batch_size = 50\nn_images=10000\n\nfor i_batch in tqdm(range(0, n_images, im_batch_size)):\n    fixed_z = np.random.uniform(-1, 1, size=(im_batch_size, Z_SIZE))\n    fixed_z = torch.from_numpy(fixed_z).float()\n    if train_on_gpu:\n        fixed_z = fixed_z.cuda()\n    gen_images = G(fixed_z)\n    images = gen_images.to(\"cpu\").clone().detach()\n    images = images.numpy().transpose(0, 2, 3, 1)\n    for i_image in range(gen_images.size(0)):\n        save_image(gen_images[i_image, :, :, :], os.path.join('../output_images', f'image_{i_batch+i_image:05d}.png'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil\nshutil.make_archive('images', 'zip', '../output_images')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}